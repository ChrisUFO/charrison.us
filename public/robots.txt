# Standard robots.txt
User-agent: *
Allow: /

# Block aggressive AI scrapers while allowing search engines
User-agent: GPTBot
Disallow: /

User-agent: CCBot
Disallow: /

# Honeypot path (if it were a real file/directory)
Disallow: /hp-trap/
